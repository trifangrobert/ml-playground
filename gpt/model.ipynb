{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class GPTconfig:\n",
    "    # block_size: int = 128\n",
    "    # vocab_size = 50257\n",
    "    # n_embd: int = 768\n",
    "    # n_layer: int = 12\n",
    "    # n_head: int = 12\n",
    "    # dropout: float = 0.0\n",
    "\n",
    "batch_size: int = 16\n",
    "block_size: int = 32\n",
    "epochs = 5000\n",
    "eval_iters = 100\n",
    "learning_rate = 1e-3\n",
    "# vocab_size = 50257\n",
    "n_embd: int = 64\n",
    "n_layer: int = 4\n",
    "n_head: int = 4\n",
    "dropout: float = 0.0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean().item()\n",
    "    model.train()  \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) # (B, T, head_size)\n",
    "        q = self.query(x) # (B, T, head_size)\n",
    "        v = self.value(x) # (B, T, head_size)\n",
    "\n",
    "        scale_value = k.shape[-1] ** -0.5\n",
    "        attention = q @ k.transpose(-2, -1) * scale_value # (B, T, T)\n",
    "\n",
    "        masked_attention = attention.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\")) # (B, T, T)\n",
    "        masked_attention = F.softmax(masked_attention, dim=-1) # (B, T, T)\n",
    "        masked_attention = self.dropout(masked_attention) # (B, T, T)\n",
    "\n",
    "        out = masked_attention @ v # (B, T, head_size)\n",
    "\n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_head, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(n_head)])\n",
    "        self.proj = nn.Linear(n_head * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        return self.dropout(self.proj(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd * 4),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(n_embd * 4, n_embd),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.self_attn = MultiHeadAttention(n_head, head_size)\n",
    "        self.feed_forward = FeedForward(n_embd)\n",
    "        self.layer_norm1 = nn.LayerNorm(n_embd)\n",
    "        self.layer_norm2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.self_attn(self.layer_norm1(x))\n",
    "        x = x + self.feed_forward(self.layer_norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embeddings = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tok_emb = self.token_embeddings(idx) # (B, T, C)\n",
    "        pos_emb = self.position_embeddings(torch.arange(T, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "\n",
    "        logits = self.head(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                      | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                              | 5/5000 [00:01<21:41,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 4.302, valid loss 4.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                          | 105/5000 [00:06<08:57,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, train loss 3.450, valid loss 3.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|██▍                                                         | 204/5000 [00:11<12:34,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200, train loss 3.365, valid loss 3.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▋                                                        | 303/5000 [00:18<24:38,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300, train loss 2.877, valid loss 3.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████▊                                                       | 402/5000 [00:30<55:08,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400, train loss 2.975, valid loss 2.897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████                                                      | 505/5000 [00:44<23:30,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500, train loss 2.761, valid loss 2.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|███████▎                                                    | 605/5000 [00:53<25:17,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600, train loss 2.679, valid loss 2.722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|████████▍                                                   | 705/5000 [01:01<22:53,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 700, train loss 2.696, valid loss 2.661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████▋                                                  | 804/5000 [01:10<17:40,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 800, train loss 2.661, valid loss 2.616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████▊                                                 | 903/5000 [01:17<19:33,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 900, train loss 2.544, valid loss 2.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████████▊                                               | 1005/5000 [01:23<14:07,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1000, train loss 2.498, valid loss 2.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████                                              | 1104/5000 [01:30<13:48,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1100, train loss 2.544, valid loss 2.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████████▏                                            | 1200/5000 [01:34<03:13, 19.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1200, train loss 2.562, valid loss 2.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████████▍                                           | 1304/5000 [01:47<12:45,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1300, train loss 2.456, valid loss 2.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████████▌                                          | 1402/5000 [01:53<16:12,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1400, train loss 2.500, valid loss 2.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|█████████████████▋                                         | 1503/5000 [02:10<43:22,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1500, train loss 2.555, valid loss 2.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████▉                                        | 1604/5000 [02:23<20:14,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1600, train loss 2.507, valid loss 2.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████                                       | 1703/5000 [02:32<19:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1700, train loss 2.562, valid loss 2.451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|█████████████████████▎                                     | 1804/5000 [02:38<10:23,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1800, train loss 2.442, valid loss 2.429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████▍                                    | 1905/5000 [02:44<08:34,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1900, train loss 2.371, valid loss 2.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████▋                                   | 2003/5000 [02:54<21:31,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2000, train loss 2.460, valid loss 2.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████▊                                  | 2105/5000 [03:02<10:12,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2100, train loss 2.520, valid loss 2.414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████                                 | 2205/5000 [03:09<13:02,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2200, train loss 2.235, valid loss 2.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████████████▏                               | 2305/5000 [03:19<13:06,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2300, train loss 2.328, valid loss 2.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████▍                              | 2407/5000 [03:26<07:10,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2400, train loss 2.307, valid loss 2.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████▌                             | 2504/5000 [03:32<09:31,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2500, train loss 2.335, valid loss 2.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████▋                            | 2605/5000 [03:39<08:44,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2600, train loss 2.345, valid loss 2.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████▉                           | 2704/5000 [03:45<07:36,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2700, train loss 2.405, valid loss 2.351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████████████████████████████████                          | 2805/5000 [03:52<08:17,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2800, train loss 2.209, valid loss 2.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████████████████████▎                        | 2904/5000 [03:59<07:19,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2900, train loss 2.436, valid loss 2.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████████████████▍                       | 3005/5000 [04:07<11:25,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3000, train loss 2.375, valid loss 2.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████████████████▋                      | 3105/5000 [04:13<06:41,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3100, train loss 2.380, valid loss 2.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████████████████▊                     | 3204/5000 [04:20<06:17,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3200, train loss 2.361, valid loss 2.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████████████████                    | 3306/5000 [04:26<05:37,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3300, train loss 2.211, valid loss 2.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████▏                  | 3404/5000 [04:32<05:18,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3400, train loss 2.291, valid loss 2.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████▎                 | 3503/5000 [04:39<08:03,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3500, train loss 2.206, valid loss 2.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████████████████▌                | 3602/5000 [04:48<13:27,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3600, train loss 2.242, valid loss 2.290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████▋               | 3703/5000 [04:57<07:31,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3700, train loss 2.278, valid loss 2.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████▉              | 3805/5000 [05:04<04:34,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3800, train loss 2.185, valid loss 2.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████             | 3905/5000 [05:11<03:57,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3900, train loss 2.180, valid loss 2.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████████████████████▏           | 4004/5000 [05:17<03:30,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4000, train loss 2.314, valid loss 2.259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████▍          | 4106/5000 [05:24<03:14,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4100, train loss 2.167, valid loss 2.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████████████████████▌         | 4205/5000 [05:31<02:50,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4200, train loss 2.184, valid loss 2.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████▊        | 4304/5000 [05:37<02:28,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4300, train loss 2.283, valid loss 2.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████▉       | 4406/5000 [05:44<02:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4400, train loss 2.235, valid loss 2.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████▏     | 4505/5000 [05:51<01:46,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4500, train loss 2.270, valid loss 2.239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|██████████████████████████████████████████████████████▎    | 4606/5000 [05:57<01:25,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4600, train loss 2.249, valid loss 2.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|███████████████████████████████████████████████████████▌   | 4705/5000 [06:04<01:01,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4700, train loss 2.090, valid loss 2.224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|████████████████████████████████████████████████████████▋  | 4804/5000 [06:10<00:40,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4800, train loss 2.200, valid loss 2.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████▊ | 4903/5000 [06:18<00:30,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4900, train loss 2.186, valid loss 2.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 5000/5000 [06:24<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4999, train loss 2.256, valid loss 2.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = GPT()\n",
    "model = model.to(device)\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                             | 4/1000 [00:01<05:49,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 2.023, valid loss 2.098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|██████▎                                                     | 106/1000 [00:06<01:37,  9.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, train loss 1.934, valid loss 2.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████▎                                               | 206/1000 [00:10<01:28,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200, train loss 2.089, valid loss 2.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████▍                                         | 307/1000 [00:15<01:13,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300, train loss 2.072, valid loss 2.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████████████████████████▍                                   | 407/1000 [00:19<01:08,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400, train loss 2.005, valid loss 2.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████▍                             | 507/1000 [00:24<00:56,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500, train loss 2.005, valid loss 2.083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████▍                       | 607/1000 [00:28<00:46,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 600, train loss 2.041, valid loss 2.077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████▎                 | 706/1000 [00:33<00:35,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 700, train loss 1.945, valid loss 2.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████████████████████████████████████████████▎           | 806/1000 [00:38<00:25,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 800, train loss 2.075, valid loss 2.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████▏     | 904/1000 [00:44<00:23,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 900, train loss 2.042, valid loss 2.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1000/1000 [00:48<00:00, 20.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1000), ncols=100):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()  \n",
    "\n",
    "    if epoch % eval_iters == 0 or epoch == epochs - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f'epoch {epoch}, train loss {loss.item():.3f}, valid loss {losses[\"val\"]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fethy ruls, for, qut.\n",
      "\n",
      "EY VINCER:\n",
      "Pow, bemres!\n",
      "Thou mure ore rump hy carept, and anlive.\n",
      "As him pante thyee ofrunt. Renges:\n",
      "I she il me desparse tuing have say Setrored,-\n",
      "O'GLIOLIUKE-\n",
      "DWHUKINA:\n",
      "Til, delly go thim\n",
      "Marbes camendy!\n",
      "Sewor' him dond a sereiid day.\n",
      "Thon your madady me thou thas toundentle.\n",
      "\n",
      "DUCTALIUCHBES:\n",
      "\n",
      "IGRGAO:\n",
      "F deacl in, love.\n",
      "\n",
      "KING TIIVM:\n",
      "I powita wor not chis is, the! the ut I'lCYoon\n",
      "\n",
      "FHORULAPE:\n",
      "\n",
      "Diest u.\n",
      "JULARIS:\n",
      "Th wing wour that kere! Thou los this tha me turcke sorough.\n",
      "\n",
      "POM! INGTEDW:\n",
      "But It ard in that diall known sities flaqied;\n",
      "Aund, cope wethe and, by have\n",
      "I'e are me diths manse bed\n",
      "Sith, all toin cissmand, my:\n",
      "sup wich caingh'd sire of\n",
      "Lor thee is kis nor well.\n",
      "QTON'US:\n",
      "Yoave ay the meake think:\n",
      "I thak\n",
      "I sthereedserpad, this leese;\n",
      "See with lictimenk exsgh mer bepte knot thootir. Save grent bearfulm? word,\n",
      "What a and in lamefner'nt, this do tuby.\n",
      "The weweld she firme lo, tho agu'g, trow rentu,--\n",
      "\n",
      "TUCES:\n",
      "Thas ha me?\n",
      "What rast'd men thorthe sullfaing awit\n",
      "Thee \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(decode(model.generate(context, max_new_tokens=1000)[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
